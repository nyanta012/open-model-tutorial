{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyanta012/open-model-tutorial/blob/main/section6/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colabの使い方\n",
        "\n",
        "- **セルの実行:** `Ctrl + Enter`, `Shift + Enter`\n",
        "- **セルの作成:** `Ctrl + M B`\n",
        "- **セルの削除:** `Ctrl + M D`"
      ],
      "metadata": {
        "id": "W3hsb5Dwqy11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "※GPUの設定が必要"
      ],
      "metadata": {
        "id": "po6uV1khq1Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ej_tvQiq1Yt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ofszPiUq1e1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hRWHOC2jqyla"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH9Ce6T2Dz2j"
      },
      "source": [
        "# モデルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install openai==0.28.1\n",
        "!pip install transformers[torch]==4.34.1 accelerate==0.24.0 InstructorEmbedding==1.0.1 sentence_transformers==2.2.2 pypdf==3.16.4 optimum==1.13.2 auto-gptq==0.4.2 llama-index==0.9.8\n",
        "\n",
        "from typing import Any, List\n",
        "\n",
        "import torch\n",
        "from InstructorEmbedding import INSTRUCTOR\n",
        "from llama_index import ServiceContext, SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_index.bridge.pydantic import PrivateAttr\n",
        "from llama_index.embeddings.base import BaseEmbedding\n",
        "from llama_index.llms import HuggingFaceLLM\n",
        "from llama_index.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "RYjSXEbtq8-F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oD6qP7bQ4hFz"
      },
      "outputs": [],
      "source": [
        "model_name = \"TheBloke/Xwin-LM-7B-V0.1-GPTQ\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=2048,\n",
        "    tokenizer_name=model_name,\n",
        "    model_name=model_name,\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"torch_dtype\": torch.float16},\n",
        "    generate_kwargs={\"temperature\": 0.01, \"do_sample\": True},\n",
        ")"
      ],
      "metadata": {
        "id": "3jgAeB7mp-oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ikloAzpqqAFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-1Jz8eTrCIc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aW9p1fevrCR7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdn7i5XCD6Ad"
      },
      "source": [
        "# ベクトル化モデルの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yH7cMDpdmFX3"
      },
      "outputs": [],
      "source": [
        "class InstructorEmbeddings(BaseEmbedding):\n",
        "    _model: INSTRUCTOR = PrivateAttr()\n",
        "    _query_prefix: str = PrivateAttr()\n",
        "    _text_prefix: str = PrivateAttr()\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        instructor_model_name: str = 'intfloat/multilingual-e5-large',\n",
        "        **kwargs: Any,\n",
        "    ) -> None:\n",
        "        self._model = INSTRUCTOR(instructor_model_name)\n",
        "        self._query_prefix = \"query:\" # multilingual-e5-largeの学習方法に準拠: https://huggingface.co/intfloat/multilingual-e5-large\n",
        "        self._text_prefix = \"passage:\" # multilingual-e5-largeの学習方法に準拠: https://huggingface.co/intfloat/multilingual-e5-large\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def class_name(cls) -> str:\n",
        "        return \"instructor\"\n",
        "\n",
        "    async def _aget_query_embedding(self, query: str) -> List[float]:\n",
        "        return self._get_query_embedding(query)\n",
        "\n",
        "    async def _aget_text_embedding(self, text: str) -> List[float]:\n",
        "        return self._get_text_embedding(text)\n",
        "\n",
        "    def _get_query_embedding(self, query: str) -> List[float]:\n",
        "        embeddings = self._model.encode([[self._query_prefix, query]])\n",
        "        return embeddings[0]\n",
        "\n",
        "    def _get_text_embedding(self, text: str) -> List[float]:\n",
        "        embeddings = self._model.encode([[self._text_prefix, text]])\n",
        "        return embeddings[0]\n",
        "\n",
        "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
        "        embeddings = self._model.encode([[self._text_prefix, text] for text in texts])\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_naylkENrDX6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I57n9yqKD9Qq"
      },
      "source": [
        "# LlamaIndexの設定"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ベクトル化モジュールの設定\n",
        "service_context = ServiceContext.from_defaults(llm=llm,\n",
        "    embed_model=InstructorEmbeddings(embed_batch_size=1), chunk_size=512\n",
        ")\n",
        "# ドキュメントをgithubからダウンロード\n",
        "!mkdir -p data\n",
        "!wget -P data https://github.com/nyanta012/open-model-tutorial/raw/main/pdf/健康のすべて.pdf\n",
        "\n",
        "# ドキュメント読み込み\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "\n",
        "# インデックスの作成\n",
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "Fz09Pq7cp7C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5fGRxsHrD4X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtpOFCfqrD9F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3fUFfbWEJd8"
      },
      "source": [
        "# プロンプトの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WCDb2m7B4yZn"
      },
      "outputs": [],
      "source": [
        "TEMPLATE =\"\"\"A chat between a curious user and an artificial intelligence assistant.\n",
        "The assistant gives helpful, detailed, and polite answers to the user's questions.\n",
        "USER: 下記の情報が与えられています。\n",
        "\\n ---------------------\\n {context_str} \\n---------------------\\n\n",
        "この情報を参照して次の質問に答えてください。情報に基づいた回答のみ生成してください。\n",
        "情報にない場合は、わからない旨を伝えてください。\n",
        "質問:{query_str} ASSISTANT:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(TEMPLATE)\n",
        "\n",
        "query_engine = index.as_query_engine(text_qa_template=PROMPT, streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vtOHVkIbrEdo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGq-hmzgrEiy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9CqOHy6EL1I"
      },
      "source": [
        "# ドキュメントを参照したQ&Aの実行"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"健康になるにはどんな運動をすると良いですか？\")\n",
        "response.print_response_stream()"
      ],
      "metadata": {
        "id": "nnoUp0U6p8uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efCv2qN9IPa0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}